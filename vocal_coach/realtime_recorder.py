"""
ì‹¤ì‹œê°„ ìŒì„± ë…¹ìŒ ë° ë¶„ì„ ëª¨ë“ˆ
ì‹¤ì œ ë§ˆì´í¬ ì…ë ¥ì„ ë°›ì•„ ì‹¤ì‹œê°„ìœ¼ë¡œ í”¼ë“œë°±ì„ ì œê³µí•˜ëŠ” ê¸°ëŠ¥
"""

import numpy as np
import sounddevice as sd
import threading
import time
import queue
from typing import Optional, Dict, Any, Callable, List
import librosa
from collections import deque

class RealtimeRecorder:
    """ì‹¤ì‹œê°„ ìŒì„± ë…¹ìŒ ë° ë¶„ì„ í´ë˜ìŠ¤"""
    
    def __init__(self, sample_rate: int = 22050, channels: int = 1, 
                 buffer_size: int = 2048):
        """ì´ˆê¸°í™”"""
        self.sample_rate = sample_rate
        self.channels = channels
        self.buffer_size = buffer_size
        
        # ë…¹ìŒ ìƒíƒœ
        self.is_recording = False
        self.is_analyzing = False
        
        # ë²„í¼
        self.audio_buffer = deque(maxlen=self.sample_rate * 10)  # ìµœëŒ€ 10ì´ˆ ì €ì¥
        self.analysis_queue = queue.Queue()
        
        # ë¶„ì„ ì„¤ì •
        self.analysis_window = 1.0  # 1ì´ˆ ë‹¨ìœ„ë¡œ ë¶„ì„
        self.min_freq = 80.0
        self.max_freq = 800.0
        
        # ì½œë°± í•¨ìˆ˜ë“¤
        self.pitch_callback = None
        self.volume_callback = None
        self.feedback_callback = None
        
        # ë¶„ì„ ìŠ¤ë ˆë“œ
        self.analysis_thread = None
        
    def start_recording(self, target_melody: Optional[Dict[str, Any]] = None,
                       pitch_callback: Optional[Callable] = None,
                       volume_callback: Optional[Callable] = None,
                       feedback_callback: Optional[Callable] = None) -> bool:
        """ì‹¤ì‹œê°„ ë…¹ìŒ ì‹œì‘"""
        try:
            # ì½œë°± í•¨ìˆ˜ ì„¤ì •
            self.pitch_callback = pitch_callback
            self.volume_callback = volume_callback
            self.feedback_callback = feedback_callback
            self.target_melody = target_melody
            
            # ë§ˆì´í¬ ì‚¬ìš© ê°€ëŠ¥ì„± í™•ì¸
            if not self._check_microphone():
                print("âŒ ë§ˆì´í¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë°ëª¨ ëª¨ë“œë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
                return False
            
            # ë²„í¼ ì´ˆê¸°í™”
            self.audio_buffer.clear()
            
            # ë…¹ìŒ ì‹œì‘
            print("ğŸ¤ ì‹¤ì‹œê°„ ë…¹ìŒ ì‹œì‘...")
            self.is_recording = True
            self.is_analyzing = True
            
            # ë¶„ì„ ìŠ¤ë ˆë“œ ì‹œì‘
            self.analysis_thread = threading.Thread(target=self._analysis_worker)
            self.analysis_thread.daemon = True
            self.analysis_thread.start()
            
            # ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì‹œì‘
            self.stream = sd.InputStream(
                callback=self._audio_callback,
                channels=self.channels,
                samplerate=self.sample_rate,
                blocksize=self.buffer_size,
                dtype=np.float32
            )
            self.stream.start()
            
            return True
            
        except Exception as e:
            print(f"âŒ ë…¹ìŒ ì‹œì‘ ì‹¤íŒ¨: {e}")
            self.is_recording = False
            self.is_analyzing = False
            return False
    
    def stop_recording(self) -> Dict[str, Any]:
        """ë…¹ìŒ ì¤‘ì§€ ë° ì „ì²´ ì˜¤ë””ì˜¤ ë°˜í™˜"""
        try:
            if self.is_recording:
                self.is_recording = False
                self.is_analyzing = False
                
                # ìŠ¤íŠ¸ë¦¼ ì¤‘ì§€
                if hasattr(self, 'stream'):
                    self.stream.stop()
                    self.stream.close()
                
                # ë¶„ì„ ìŠ¤ë ˆë“œ ì¢…ë£Œ ëŒ€ê¸°
                if self.analysis_thread and self.analysis_thread.is_alive():
                    self.analysis_thread.join(timeout=2.0)
                
                # ì „ì²´ ì˜¤ë””ì˜¤ ë°ì´í„° ë°˜í™˜
                if len(self.audio_buffer) > 0:
                    full_audio = np.array(list(self.audio_buffer))
                    return {
                        'audio': full_audio,
                        'sr': self.sample_rate,
                        'duration': len(full_audio) / self.sample_rate,
                        'channels': self.channels,
                        'timestamp': time.time()
                    }
                else:
                    return None
                    
        except Exception as e:
            print(f"âŒ ë…¹ìŒ ì¤‘ì§€ ì‹¤íŒ¨: {e}")
            return None
    
    def _check_microphone(self) -> bool:
        """ë§ˆì´í¬ ì‚¬ìš© ê°€ëŠ¥ì„± í™•ì¸"""
        try:
            devices = sd.query_devices()
            input_devices = [d for d in devices if d['max_input_channels'] > 0]
            
            if len(input_devices) == 0:
                return False
            
            # ê¸°ë³¸ ì…ë ¥ ì¥ì¹˜ í…ŒìŠ¤íŠ¸
            test_duration = 0.1
            try:
                test_audio = sd.rec(
                    int(test_duration * self.sample_rate), 
                    samplerate=self.sample_rate, 
                    channels=self.channels,
                    dtype=np.float32
                )
                sd.wait()
                return True
            except:
                return False
                
        except Exception:
            return False
    
    def _audio_callback(self, indata, frames, time, status):
        """ì˜¤ë””ì˜¤ ì…ë ¥ ì½œë°±"""
        if status:
            print(f"ì˜¤ë””ì˜¤ ìƒíƒœ: {status}")
        
        if self.is_recording:
            # ëª¨ë…¸ ë³€í™˜
            if indata.shape[1] > 1:
                audio_mono = np.mean(indata, axis=1)
            else:
                audio_mono = indata[:, 0]
            
            # ë²„í¼ì— ì¶”ê°€
            self.audio_buffer.extend(audio_mono)
            
            # ë¶„ì„ì„ ìœ„í•´ íì— ì¶”ê°€
            if len(audio_mono) > 0:
                self.analysis_queue.put(audio_mono.copy())
    
    def _analysis_worker(self):
        """ì‹¤ì‹œê°„ ë¶„ì„ ì›Œì»¤ ìŠ¤ë ˆë“œ"""
        analysis_buffer = deque(maxlen=int(self.sample_rate * self.analysis_window))
        
        while self.is_analyzing:
            try:
                # íì—ì„œ ì˜¤ë””ì˜¤ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
                try:
                    audio_chunk = self.analysis_queue.get(timeout=0.1)
                    analysis_buffer.extend(audio_chunk)
                except queue.Empty:
                    continue
                
                # ì¶©ë¶„í•œ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ë¶„ì„ ìˆ˜í–‰
                if len(analysis_buffer) >= int(self.sample_rate * self.analysis_window):
                    audio_data = np.array(list(analysis_buffer))
                    
                    # ì‹¤ì‹œê°„ ë¶„ì„
                    analysis_result = self._analyze_realtime(audio_data)
                    
                    # ì½œë°± í˜¸ì¶œ
                    self._call_callbacks(analysis_result)
                    
                    # ë²„í¼ ì¼ë¶€ ì œê±° (ì¤‘ë³µ ë°©ì§€)
                    remove_count = len(audio_chunk)
                    for _ in range(min(remove_count, len(analysis_buffer))):
                        analysis_buffer.popleft()
                
            except Exception as e:
                print(f"ì‹¤ì‹œê°„ ë¶„ì„ ì˜¤ë¥˜: {e}")
                time.sleep(0.1)
    
    def _analyze_realtime(self, audio_data: np.ndarray) -> Dict[str, Any]:
        """ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ë¶„ì„"""
        try:
            result = {}
            
            # 1. ìŒì • ë¶„ì„
            pitch_info = self._extract_pitch_realtime(audio_data)
            result['pitch'] = pitch_info
            
            # 2. ìŒëŸ‰ ë¶„ì„
            volume_info = self._analyze_volume_realtime(audio_data)
            result['volume'] = volume_info
            
            # 3. ì•ˆì •ì„± ë¶„ì„
            stability_info = self._analyze_stability_realtime(audio_data)
            result['stability'] = stability_info
            
            # 4. ëª©í‘œ ë©œë¡œë””ì™€ ë¹„êµ (ìˆëŠ” ê²½ìš°)
            if self.target_melody:
                comparison = self._compare_with_target(pitch_info, self.target_melody)
                result['comparison'] = comparison
            
            return result
            
        except Exception as e:
            return {'error': f'ì‹¤ì‹œê°„ ë¶„ì„ ì‹¤íŒ¨: {e}'}
    
    def _extract_pitch_realtime(self, audio: np.ndarray) -> Dict[str, Any]:
        """ì‹¤ì‹œê°„ ìŒì • ì¶”ì¶œ"""
        try:
            # ìŠ¤í™íŠ¸ë¡œê·¸ë¨ ê³„ì‚°
            stft = librosa.stft(audio, n_fft=1024, hop_length=256)
            pitches, magnitudes = librosa.piptrack(
                S=np.abs(stft), sr=self.sample_rate, 
                fmin=self.min_freq, fmax=self.max_freq, threshold=0.1
            )
            
            # ì£¼ìš” í”¼ì¹˜ ì¶”ì¶œ
            pitch_values = []
            confidence_values = []
            
            for t in range(pitches.shape[1]):
                index = magnitudes[:, t].argmax()
                pitch = pitches[index, t]
                confidence = magnitudes[index, t]
                
                if pitch > 0:
                    pitch_values.append(pitch)
                    confidence_values.append(confidence)
            
            if len(pitch_values) > 0:
                avg_pitch = np.mean(pitch_values)
                pitch_stability = 1.0 - (np.std(pitch_values) / (avg_pitch + 1e-8))
                avg_confidence = np.mean(confidence_values)
            else:
                avg_pitch = 0.0
                pitch_stability = 0.0
                avg_confidence = 0.0
            
            return {
                'frequency': avg_pitch,
                'stability': max(0.0, pitch_stability),
                'confidence': avg_confidence,
                'note': self._frequency_to_note(avg_pitch) if avg_pitch > 0 else None
            }
            
        except Exception as e:
            return {'error': f'ìŒì • ì¶”ì¶œ ì‹¤íŒ¨: {e}'}
    
    def _analyze_volume_realtime(self, audio: np.ndarray) -> Dict[str, Any]:
        """ì‹¤ì‹œê°„ ìŒëŸ‰ ë¶„ì„"""
        try:
            # RMS ê³„ì‚°
            rms = np.sqrt(np.mean(audio**2))
            
            # dB ë³€í™˜
            db = 20 * np.log10(rms + 1e-8)
            
            # ì •ê·œí™”ëœ ë³¼ë¥¨ (0-1)
            normalized_volume = max(0.0, min(1.0, (db + 60) / 60))
            
            return {
                'rms': rms,
                'db': db,
                'normalized': normalized_volume,
                'level': self._get_volume_level(normalized_volume)
            }
            
        except Exception as e:
            return {'error': f'ìŒëŸ‰ ë¶„ì„ ì‹¤íŒ¨: {e}'}
    
    def _analyze_stability_realtime(self, audio: np.ndarray) -> Dict[str, Any]:
        """ì‹¤ì‹œê°„ ì•ˆì •ì„± ë¶„ì„"""
        try:
            # ì—ë„ˆì§€ ë³€í™”ìœ¨ ê³„ì‚°
            frame_size = len(audio) // 10
            energy_frames = []
            
            for i in range(0, len(audio) - frame_size, frame_size):
                frame = audio[i:i + frame_size]
                energy = np.sum(frame**2)
                energy_frames.append(energy)
            
            if len(energy_frames) > 1:
                energy_stability = 1.0 - (np.std(energy_frames) / (np.mean(energy_frames) + 1e-8))
            else:
                energy_stability = 0.5
            
            return {
                'energy_stability': max(0.0, energy_stability),
                'overall_stability': max(0.0, energy_stability)
            }
            
        except Exception as e:
            return {'error': f'ì•ˆì •ì„± ë¶„ì„ ì‹¤íŒ¨: {e}'}
    
    def _compare_with_target(self, pitch_info: Dict[str, Any], 
                           target_melody: Dict[str, Any]) -> Dict[str, Any]:
        """ëª©í‘œ ë©œë¡œë””ì™€ ë¹„êµ"""
        try:
            current_freq = pitch_info.get('frequency', 0)
            
            if current_freq <= 0:
                return {'accuracy': 0.0, 'message': 'ìŒì„±ì´ ê°ì§€ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤'}
            
            # ëª©í‘œ ì£¼íŒŒìˆ˜ ì¤‘ì—ì„œ ê°€ì¥ ê°€ê¹Œìš´ ê°’ ì°¾ê¸°
            target_freqs = target_melody.get('frequencies', [])
            if len(target_freqs) == 0:
                return {'accuracy': 0.5, 'message': 'ëª©í‘œ ë©œë¡œë””ê°€ ì—†ìŠµë‹ˆë‹¤'}
            
            # í˜„ì¬ ì‹œì ì—ì„œ ì˜ˆìƒë˜ëŠ” ëª©í‘œ ì£¼íŒŒìˆ˜ ê³„ì‚°
            # (ì‹¤ì œë¡œëŠ” ì‹œê°„ ë™ê¸°í™”ê°€ í•„ìš”í•˜ì§€ë§Œ, ì—¬ê¸°ì„œëŠ” í‰ê· ê°’ ì‚¬ìš©)
            target_freq = np.mean(target_freqs[target_freqs > 0])
            
            if target_freq <= 0:
                return {'accuracy': 0.5, 'message': 'ìœ íš¨í•œ ëª©í‘œ ìŒì •ì´ ì—†ìŠµë‹ˆë‹¤'}
            
            # ì„¼íŠ¸ ë‹¨ìœ„ë¡œ ì˜¤ì°¨ ê³„ì‚°
            cent_error = 1200 * np.log2(current_freq / target_freq)
            accuracy = max(0.0, 1.0 - abs(cent_error) / 100.0)
            
            # í”¼ë“œë°± ë©”ì‹œì§€ ìƒì„±
            if abs(cent_error) <= 20:
                message = "ğŸ¯ ì •í™•í•©ë‹ˆë‹¤!"
            elif cent_error > 20:
                message = f"ğŸ“ˆ ë„ˆë¬´ ë†’ìŠµë‹ˆë‹¤ ({cent_error:.0f}ì„¼íŠ¸)"
            else:
                message = f"ğŸ“‰ ë„ˆë¬´ ë‚®ìŠµë‹ˆë‹¤ ({abs(cent_error):.0f}ì„¼íŠ¸)"
            
            return {
                'accuracy': accuracy,
                'cent_error': cent_error,
                'message': message,
                'target_freq': target_freq,
                'current_freq': current_freq
            }
            
        except Exception as e:
            return {'error': f'ë¹„êµ ë¶„ì„ ì‹¤íŒ¨: {e}'}
    
    def _frequency_to_note(self, frequency: float) -> str:
        """ì£¼íŒŒìˆ˜ë¥¼ ìŒí‘œë¡œ ë³€í™˜"""
        try:
            if frequency <= 0:
                return "None"
            
            # A4 = 440Hz ê¸°ì¤€
            A4 = 440.0
            note_names = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']
            
            # ë°˜ìŒ ê³„ì‚°
            semitones_from_A4 = 12 * np.log2(frequency / A4)
            note_index = int(round(semitones_from_A4)) % 12
            octave = 4 + int(round(semitones_from_A4)) // 12
            
            return f"{note_names[note_index]}{octave}"
            
        except Exception:
            return "Unknown"
    
    def _get_volume_level(self, normalized_volume: float) -> str:
        """ì •ê·œí™”ëœ ë³¼ë¥¨ì„ ë ˆë²¨ë¡œ ë³€í™˜"""
        if normalized_volume < 0.1:
            return "ë§¤ìš° ì‘ìŒ"
        elif normalized_volume < 0.3:
            return "ì‘ìŒ"
        elif normalized_volume < 0.7:
            return "ì ë‹¹"
        elif normalized_volume < 0.9:
            return "í¼"
        else:
            return "ë§¤ìš° í¼"
    
    def _call_callbacks(self, analysis_result: Dict[str, Any]):
        """ì½œë°± í•¨ìˆ˜ë“¤ í˜¸ì¶œ"""
        try:
            if self.pitch_callback and 'pitch' in analysis_result:
                self.pitch_callback(analysis_result['pitch'])
            
            if self.volume_callback and 'volume' in analysis_result:
                self.volume_callback(analysis_result['volume'])
            
            if self.feedback_callback:
                self.feedback_callback(analysis_result)
                
        except Exception as e:
            print(f"ì½œë°± í˜¸ì¶œ ì˜¤ë¥˜: {e}")
    
    def list_audio_devices(self):
        """ì‚¬ìš© ê°€ëŠ¥í•œ ì˜¤ë””ì˜¤ ì¥ì¹˜ ëª©ë¡"""
        try:
            print("\nğŸ¤ ì‚¬ìš© ê°€ëŠ¥í•œ ì˜¤ë””ì˜¤ ì¥ì¹˜:")
            devices = sd.query_devices()
            
            for i, device in enumerate(devices):
                if device['max_input_channels'] > 0:
                    print(f"  {i}: {device['name']} (ì…ë ¥ ì±„ë„: {device['max_input_channels']})")
            
            return devices
            
        except Exception as e:
            print(f"ì¥ì¹˜ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []
    
    def set_input_device(self, device_id: int):
        """ì…ë ¥ ì¥ì¹˜ ì„¤ì •"""
        try:
            sd.default.device[0] = device_id
            print(f"ì…ë ¥ ì¥ì¹˜ê°€ {device_id}ë²ˆìœ¼ë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"ì¥ì¹˜ ì„¤ì • ì‹¤íŒ¨: {e}")
