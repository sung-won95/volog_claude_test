"""
ë©œë¡œë”” ë¶„ì„ ëª¨ë“ˆ
ì˜¤ë””ì˜¤ì—ì„œ ë©œë¡œë”” ë¼ì¸ ì¶”ì¶œ ë° ë¶„ì„ ê¸°ëŠ¥ ì œê³µ
"""

import numpy as np
import librosa
from typing import Dict, Any, Optional, Tuple
from scipy.signal import medfilt
import matplotlib.pyplot as plt

class MelodyAnalyzer:
    """ë©œë¡œë”” ë¶„ì„ í´ë˜ìŠ¤"""
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.min_freq = 80.0    # ìµœì†Œ ì£¼íŒŒìˆ˜ (Hz)
        self.max_freq = 800.0   # ìµœëŒ€ ì£¼íŒŒìˆ˜ (Hz)
        self.frame_length = 2048
        self.hop_length = 512
        
    def extract_melody(self, audio_data: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """
        ì˜¤ë””ì˜¤ì—ì„œ ë©œë¡œë”” ì¶”ì¶œ
        
        Args:
            audio_data: ì˜¤ë””ì˜¤ ë°ì´í„°
            
        Returns:
            ë©œë¡œë”” ë°ì´í„° ë˜ëŠ” None
        """
        try:
            audio = audio_data['audio']
            sr = audio_data['sr']
            
            print("ğŸ¼ ë©œë¡œë”” ì¶”ì¶œ ì¤‘...")
            
            # 1. ê¸°ë³¸ ì£¼íŒŒìˆ˜(F0) ì¶”ì¶œ
            f0_times, f0_values = self._extract_f0(audio, sr)
            
            # 2. ë…¸ì´ì¦ˆ ì œê±° ë° ìŠ¤ë¬´ë”©
            f0_values = self._smooth_f0(f0_values)
            
            # 3. ì‹ ë¢°ë„ ê³„ì‚°
            confidence = self._calculate_confidence(audio, sr, f0_times, f0_values)
            
            # 4. ìŒí‘œ ë‹¨ìœ„ ë¶„í• 
            notes = self._segment_notes(f0_times, f0_values, confidence)
            
            melody_data = {
                'times': f0_times,
                'frequencies': f0_values,
                'confidence': confidence,
                'notes': notes,
                'sr': sr
            }
            
            print(f"âœ… ë©œë¡œë”” ì¶”ì¶œ ì™„ë£Œ ({len(f0_times)}ê°œ í”„ë ˆì„)")
            return melody_data
            
        except Exception as e:
            print(f"âŒ ë©œë¡œë”” ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return None
    
    def _extract_f0(self, audio: np.ndarray, sr: int) -> Tuple[np.ndarray, np.ndarray]:
        """
        ê¸°ë³¸ ì£¼íŒŒìˆ˜(F0) ì¶”ì¶œ - librosaì˜ piptrack ì‚¬ìš©
        
        Args:
            audio: ì˜¤ë””ì˜¤ ì‹ í˜¸
            sr: ìƒ˜í”Œë§ ë ˆì´íŠ¸
            
        Returns:
            ì‹œê°„ ë°°ì—´, ì£¼íŒŒìˆ˜ ë°°ì—´
        """
        # STFT ê³„ì‚°
        stft = librosa.stft(audio, n_fft=self.frame_length, hop_length=self.hop_length)
        
        # Pitch tracking
        pitches, magnitudes = librosa.piptrack(
            S=np.abs(stft),
            sr=sr,
            fmin=self.min_freq,
            fmax=self.max_freq,
            threshold=0.1
        )
        
        # ì‹œê°„ ì¶• ìƒì„±
        times = librosa.frames_to_time(
            np.arange(pitches.shape[1]), 
            sr=sr, 
            hop_length=self.hop_length
        )
        
        # ê° ì‹œê°„ í”„ë ˆì„ì—ì„œ ê°€ì¥ ê°•í•œ í”¼ì¹˜ ì„ íƒ
        f0_values = []
        for t in range(pitches.shape[1]):
            index = magnitudes[:, t].argmax()
            pitch = pitches[index, t]
            
            # ìœ íš¨í•œ í”¼ì¹˜ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ ì¶”ê°€
            if pitch > 0:
                f0_values.append(pitch)
            else:
                # ì´ì „ ê°’ìœ¼ë¡œ ë³´ê°„í•˜ê±°ë‚˜ 0ìœ¼ë¡œ ì„¤ì •
                if len(f0_values) > 0:
                    f0_values.append(f0_values[-1])
                else:
                    f0_values.append(0.0)
        
        return times, np.array(f0_values)
    
    def _smooth_f0(self, f0_values: np.ndarray, window_size: int = 5) -> np.ndarray:
        """
        F0 ê°’ ìŠ¤ë¬´ë”©
        
        Args:
            f0_values: ì›ë³¸ F0 ê°’ë“¤
            window_size: í•„í„° ìœˆë„ìš° í¬ê¸°
            
        Returns:
            ìŠ¤ë¬´ë”©ëœ F0 ê°’ë“¤
        """
        # 0ì´ ì•„ë‹Œ ê°’ë“¤ë§Œ í•„í„°ë§
        valid_mask = f0_values > 0
        
        if np.sum(valid_mask) < 3:
            return f0_values
        
        # ë©”ë””ì•ˆ í•„í„° ì ìš©
        smoothed = f0_values.copy()
        valid_f0 = f0_values[valid_mask]
        
        if len(valid_f0) > window_size:
            smoothed_valid = medfilt(valid_f0, kernel_size=window_size)
            smoothed[valid_mask] = smoothed_valid
        
        return smoothed
    
    def _calculate_confidence(self, audio: np.ndarray, sr: int, 
                            times: np.ndarray, f0_values: np.ndarray) -> np.ndarray:
        """
        ë©œë¡œë”” ì‹ ë¢°ë„ ê³„ì‚°
        
        Args:
            audio: ì˜¤ë””ì˜¤ ì‹ í˜¸
            sr: ìƒ˜í”Œë§ ë ˆì´íŠ¸
            times: ì‹œê°„ ë°°ì—´
            f0_values: ì£¼íŒŒìˆ˜ ë°°ì—´
            
        Returns:
            ì‹ ë¢°ë„ ë°°ì—´
        """
        confidence = np.zeros_like(f0_values)
        
        # ìŠ¤í™íŠ¸ë¡œê·¸ë¨ ê³„ì‚°
        stft = librosa.stft(audio, n_fft=self.frame_length, hop_length=self.hop_length)
        magnitude = np.abs(stft)
        
        for i, (time, freq) in enumerate(zip(times, f0_values)):
            if freq > 0:
                # í•´ë‹¹ ì£¼íŒŒìˆ˜ì—ì„œì˜ ì—ë„ˆì§€ ê³„ì‚°
                freq_bin = int(freq * self.frame_length / sr)
                frame_idx = min(i, magnitude.shape[1] - 1)
                
                if freq_bin < magnitude.shape[0]:
                    # ê¸°ë³¸ ì£¼íŒŒìˆ˜ì™€ í•˜ëª¨ë‹‰ì˜ ì—ë„ˆì§€ ë¹„ìœ¨ë¡œ ì‹ ë¢°ë„ ê³„ì‚°
                    fundamental_energy = magnitude[freq_bin, frame_idx]
                    
                    # ì£¼ë³€ ì£¼íŒŒìˆ˜ ë¹ˆë“¤ì˜ í‰ê·  ì—ë„ˆì§€
                    window = 3
                    start_bin = max(0, freq_bin - window)
                    end_bin = min(magnitude.shape[0], freq_bin + window + 1)
                    local_energy = np.mean(magnitude[start_bin:end_bin, frame_idx])
                    
                    # ì „ì²´ í”„ë ˆì„ì˜ í‰ê·  ì—ë„ˆì§€
                    total_energy = np.mean(magnitude[:, frame_idx])
                    
                    if total_energy > 0:
                        confidence[i] = min(1.0, local_energy / (total_energy + 1e-8))
                    else:
                        confidence[i] = 0.0
                else:
                    confidence[i] = 0.0
            else:
                confidence[i] = 0.0
        
        return confidence
    
    def _segment_notes(self, times: np.ndarray, f0_values: np.ndarray, 
                      confidence: np.ndarray, min_note_duration: float = 0.1) -> list:
        """
        ì—°ì†ëœ F0ë¥¼ ìŒí‘œ ë‹¨ìœ„ë¡œ ë¶„í• 
        
        Args:
            times: ì‹œê°„ ë°°ì—´
            f0_values: ì£¼íŒŒìˆ˜ ë°°ì—´
            confidence: ì‹ ë¢°ë„ ë°°ì—´
            min_note_duration: ìµœì†Œ ìŒí‘œ ê¸¸ì´ (ì´ˆ)
            
        Returns:
            ìŒí‘œ ë¦¬ìŠ¤íŠ¸
        """
        notes = []
        
        if len(f0_values) == 0:
            return notes
        
        # ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” êµ¬ê°„ë§Œ ì¶”ì¶œ
        valid_mask = (f0_values > 0) & (confidence > 0.3)
        
        if not np.any(valid_mask):
            return notes
        
        # ì—°ì†ëœ êµ¬ê°„ ì°¾ê¸°
        segments = []
        start_idx = None
        
        for i, is_valid in enumerate(valid_mask):
            if is_valid and start_idx is None:
                start_idx = i
            elif not is_valid and start_idx is not None:
                segments.append((start_idx, i - 1))
                start_idx = None
        
        # ë§ˆì§€ë§‰ êµ¬ê°„ ì²˜ë¦¬
        if start_idx is not None:
            segments.append((start_idx, len(valid_mask) - 1))
        
        # ê° êµ¬ê°„ì„ ìŒí‘œë¡œ ë³€í™˜
        for start_idx, end_idx in segments:
            if start_idx >= len(times) or end_idx >= len(times):
                continue
                
            duration = times[end_idx] - times[start_idx]
            
            if duration >= min_note_duration:
                segment_f0 = f0_values[start_idx:end_idx + 1]
                segment_conf = confidence[start_idx:end_idx + 1]
                
                # ê°€ì¤‘ í‰ê· ìœ¼ë¡œ ëŒ€í‘œ ì£¼íŒŒìˆ˜ ê³„ì‚°
                weights = segment_conf
                if np.sum(weights) > 0:
                    avg_freq = np.average(segment_f0, weights=weights)
                else:
                    avg_freq = np.mean(segment_f0)
                
                note = {
                    'start_time': times[start_idx],
                    'end_time': times[end_idx],
                    'duration': duration,
                    'frequency': avg_freq,
                    'midi_note': self._freq_to_midi(avg_freq),
                    'confidence': np.mean(segment_conf)
                }
                
                notes.append(note)
        
        return notes
    
    def _freq_to_midi(self, frequency: float) -> int:
        """
        ì£¼íŒŒìˆ˜ë¥¼ MIDI ë…¸íŠ¸ ë²ˆí˜¸ë¡œ ë³€í™˜
        
        Args:
            frequency: ì£¼íŒŒìˆ˜ (Hz)
            
        Returns:
            MIDI ë…¸íŠ¸ ë²ˆí˜¸
        """
        if frequency <= 0:
            return 0
        
        # A4 = 440Hz = MIDI 69
        midi_note = 69 + 12 * np.log2(frequency / 440.0)
        return int(round(midi_note))
    
    def _midi_to_freq(self, midi_note: int) -> float:
        """
        MIDI ë…¸íŠ¸ ë²ˆí˜¸ë¥¼ ì£¼íŒŒìˆ˜ë¡œ ë³€í™˜
        
        Args:
            midi_note: MIDI ë…¸íŠ¸ ë²ˆí˜¸
            
        Returns:
            ì£¼íŒŒìˆ˜ (Hz)
        """
        return 440.0 * (2 ** ((midi_note - 69) / 12.0))
    
    def analyze_melody_features(self, melody_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        ë©œë¡œë”” íŠ¹ì§• ë¶„ì„
        
        Args:
            melody_data: ë©œë¡œë”” ë°ì´í„°
            
        Returns:
            ë¶„ì„ëœ íŠ¹ì§•ë“¤
        """
        try:
            f0_values = melody_data['frequencies']
            confidence = melody_data['confidence']
            notes = melody_data.get('notes', [])
            
            # ê¸°ë³¸ í†µê³„
            valid_f0 = f0_values[f0_values > 0]
            
            if len(valid_f0) == 0:
                return {'error': 'ìœ íš¨í•œ ë©œë¡œë”” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤'}
            
            features = {
                'pitch_range': {
                    'min_freq': float(np.min(valid_f0)),
                    'max_freq': float(np.max(valid_f0)),
                    'range_semitones': self._freq_to_midi(np.max(valid_f0)) - 
                                     self._freq_to_midi(np.min(valid_f0))
                },
                'pitch_statistics': {
                    'mean_freq': float(np.mean(valid_f0)),
                    'median_freq': float(np.median(valid_f0)),
                    'std_freq': float(np.std(valid_f0))
                },
                'stability': {
                    'mean_confidence': float(np.mean(confidence)),
                    'pitch_stability': self._calculate_pitch_stability(valid_f0)
                },
                'note_count': len(notes),
                'coverage': len(valid_f0) / len(f0_values) if len(f0_values) > 0 else 0
            }
            
            return features
            
        except Exception as e:
            return {'error': f'íŠ¹ì§• ë¶„ì„ ì‹¤íŒ¨: {e}'}
    
    def _calculate_pitch_stability(self, f0_values: np.ndarray) -> float:
        """
        í”¼ì¹˜ ì•ˆì •ì„± ê³„ì‚° (ì‘ì„ìˆ˜ë¡ ì•ˆì •)
        
        Args:
            f0_values: ì£¼íŒŒìˆ˜ ê°’ë“¤
            
        Returns:
            ì•ˆì •ì„± ì§€ìˆ˜
        """
        if len(f0_values) < 2:
            return 0.0
        
        # ì—°ì†ëœ ê°’ë“¤ ê°„ì˜ ë³€í™”ìœ¨ ê³„ì‚°
        diff = np.diff(f0_values)
        relative_diff = np.abs(diff) / (f0_values[:-1] + 1e-8)
        
        # í‰ê·  ë³€í™”ìœ¨ (ë°±ë¶„ìœ¨)
        stability = np.mean(relative_diff) * 100
        
        return float(stability)
    
    def visualize_melody(self, melody_data: Dict[str, Any], title: str = "ë©œë¡œë”” ë¶„ì„") -> None:
        """
        ë©œë¡œë”” ì‹œê°í™”
        
        Args:
            melody_data: ë©œë¡œë”” ë°ì´í„°
            title: ê·¸ë˜í”„ ì œëª©
        """
        try:
            times = melody_data['times']
            frequencies = melody_data['frequencies']
            confidence = melody_data['confidence']
            
            fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))
            
            # ìƒë‹¨: ì£¼íŒŒìˆ˜ ê³¡ì„ 
            valid_mask = frequencies > 0
            ax1.plot(times[valid_mask], frequencies[valid_mask], 'b-', linewidth=1.5, alpha=0.8)
            ax1.set_ylabel('ì£¼íŒŒìˆ˜ (Hz)')
            ax1.set_title(title)
            ax1.grid(True, alpha=0.3)
            
            # ìŒí‘œ í‘œì‹œ
            notes = melody_data.get('notes', [])
            for note in notes:
                ax1.axhspan(note['frequency'] * 0.98, note['frequency'] * 1.02, 
                           xmin=(note['start_time'] - times[0]) / (times[-1] - times[0]),
                           xmax=(note['end_time'] - times[0]) / (times[-1] - times[0]),
                           alpha=0.3, color='red')
            
            # í•˜ë‹¨: ì‹ ë¢°ë„
            ax2.fill_between(times, confidence, alpha=0.6, color='green')
            ax2.set_xlabel('ì‹œê°„ (ì´ˆ)')
            ax2.set_ylabel('ì‹ ë¢°ë„')
            ax2.set_ylim(0, 1)
            ax2.grid(True, alpha=0.3)
            
            plt.tight_layout()
            plt.show()
            
        except Exception as e:
            print(f"âŒ ë©œë¡œë”” ì‹œê°í™” ì‹¤íŒ¨: {e}")
